---
counter: True   
---

# AutoDAN：基于遗传算法的LLM越狱攻击

<div class="badges">
<span class="badge full-implement-badge">已完成</span>
</div>

!!! Brief
    ![](https://david-pigeon.github.io/notebook/images/Paper/Jail/Autodan_0.png)
    
    * Paper: [AutoDAN: Generating Stealthy Jailbreak Prompts on Aligned Large Language Models](https://arxiv.org/abs/2310.04451)
    * Code: [AutoDAN](https://github.com/SheltonLiu-N/AutoDAN)
    * 该工作已被ICLR 2024接收
    * GCG的优化：生成可读性较强的对抗性攻击后缀
    * 本文中的图片均来自论文。

## Abstract

文件介绍了一种名为 AutoDAN 的新型越狱攻击,它可以自动生成隐蔽的提示来绕过对齐的大型语言模型(LLMs)的安全功能。关键要点如下:

- 介绍了 AutoDAN,这是一种针对对齐 LLMs 的新型越狱攻击,可以自动生成隐蔽的提示。
- 提出了一种针对结构化离散数据(如提示文本)的分层遗传算法,以解决从手工制作的提示初始化的细粒度空间进行搜索的挑战。
- 证明了 AutoDAN 在攻击强度、可迁移性和针对 LLMs 的普遍性方面优于基线方法。
- 表明 AutoDAN 可以有效绕过基于困惑度的防御,而之前的基于token级别的越狱攻击做不到。

## 拟解决的问题和创新点

### 现阶段越狱技术存在的问题

对齐的大语言模型是强大的语言处理和决策工具，然而即使是通过对齐技术19训练微调的大模型仍然容易受到越狱攻击。对越狱提示的研究可以引导我们深入了解LLM的局限性，并指导我们进一步构建安全可用的大语言模型。不过现如今，不论是以DAN为代表的人工设计的越狱提示，或是以GCG方法为代表的自动化越狱技术，均存在如下问题：

首先，像 GCG 这样的自动攻击不可避免地需要一种以标记的梯度信息为指导的搜索方案。虽然它提供了一种自动生成越狱提示的方法，但这导致了一个固有的缺陷：它们生成的越狱提示往往是由无意义的序列或胡言乱语组成的，即没有任何语义。这一严重缺陷使它们极易受到基于困惑度检测等朴素简单的防御机制 的攻击。

其次，尽管如DAN等人工攻击可以发现隐蔽性越狱提示，但越狱提示往往是由单个 LLM 用户手工制作的 ，因此面临着可扩展性和适应性的挑战。此外，这些方法可能无法快速适应更新的 LLM，从而降低了其随时间推移的有效性。

基于以上两大越狱技术目前的困境，一种能够自动生成隐蔽越狱提示的新方法值得大家进一步探索，这也是针对对齐LLM的新型越狱攻击AutoDAN的设计初衷。

### AutoDAN 创新点

AutoDAN 是专为提示文本等结构化离散数据定制的分层遗传算法，其含义是“自动生成类似 DAN 系列的越狱提示”。AutoDAN的主要贡献是：

- 介绍了针对 LLM 的新型高效隐形越狱攻击—AutoDAN，将隐形越狱攻击概念化为一个优化过程，并提出了基于遗传算法的方法来解决优化过程。

- 为了应对在由手工提示初始化的细粒度空间内进行搜索的挑战，提出了为结构化离散数据定制的专门函数，以确保优化过程中的收敛性和多样性。

- 经过综合评估，AutoDAN 在开源和商业 LLM 的越狱方面都表现出色，并在可移植性和通用性方面取得了显著成效。AutoDAN 的攻击强度比基线方法高出 60%，并且对困惑性防御具有免疫力。

下图展示了AutoDAN这一方法的框架和主要流程，同时也展示了在开源大模型Llama2 上，AutoDAN相比GCG方法更好的攻击强度和对困惑度检测的免疫力。

![Overview](https://david-pigeon.github.io/notebook/images/Paper/Jail/Autodan_1.png)

## 算法原理介绍

### 前置定义

在介绍AutoDAN的具体方法之前，我们首先定义越狱攻击的威胁模型和形式化表达。

#### 威胁模型

如前文所提及的，越狱攻击的主要目的是破坏 LLM 的人为对齐值或模型开发者施加的其他限制，迫使它们用正确答案而不是拒绝回答攻击者提出的恶意问题。更具体直观地解释，对于一个恶意问题集合 $Q = \{Q_1,Q_2,\cdots,Q_n \}$，攻击者会考虑用越狱提示 $J = \{ J_1,J_2,\cdots, J_n \} $来对上述问题进行描述和包装，形成最终的大语言模型输入 $T = \{ T_i = \langle J_i, Q_i \rangle \}_{i = 1,2,\cdots, n}$。加入越狱提示的恶意问题输入到大模型后，会产生回答集 $R = \{ R_1, R_2, \cdots, R_n \}$。越狱攻击的目的是确保 $R$ 中的回复主要是与 $Q$ 中的恶意问题密切相关的答案，而不是与人类价值观一致的拒绝信息。

#### 建模

显然，直接设定单个恶意问题的目标响应是不切实际的,因为很难确定合适的答案,并且可能会影响到其他问题的泛化性。AutoDAN在问题建模上采用了类似于 GCG 的方法，即将目标响应设定为以固定前缀(如"Sure, here is how to [Qi]")开头的肯定性回答 。这样可以将攻击损失函数表示为条件概率的形式。

给定一个由m个tokens组成的输入序列 $<x_1,x_2,\ldots,x_m>$，LLM会估计下一个token $x_{m+1}$ 的概率分布：

$$
x_{m+j} \sim P(\cdot | x_1,x-2,\cdots, x_{m+j-1}), j = 1,2,\cdots,k\;\;\;\;(1)
$$

越狱攻击的目标是促使模型生成以特定tokens $<r_{m+1},r_{m+2},\ldots,r_{m+k}>$ 开头的输出，即固定前缀"Sure, here is how to [Qi]"对应的tokens。因此优化目标是最大化条件概率：

$$
P(r_{m+1}, r_{m+2}, \cdots, r_{m+k} | t_1,t_2,\cdots, t_m) = \prod_{j=1}^k P(r_{m+j}|t_1,t_2,\cdots,t_m,r_{m+1},\cdots, r_{m+j})\;\;\;\;\;(2)
$$

### AutoDAN方法概要

虽然目前的越狱方法有其局限性，但从另一个角度来看，现有的人工设计越狱方法提供了一个宝贵的起点，而自动越狱方法（如GCG）则引入了一个分数函数，可指导越狱提示词的优化。因此，AutoDAN方法利用手工制作的越狱提示（如 DAN 系列）作为有语义意义的越狱提示的初始点，因为它能在更接近潜在解决方案的空间中探索越狱提示。一旦我们有了初始化的搜索空间，就可以采用基于分数函数的进化算法（如遗传算法）来识别能够有效入侵受害者 LLM 的越狱提示。

### 种群初始化策略

初始化策略在遗传算法中起着举足轻重的作用，因为它能显著影响算法的收敛速度和最终解决方案的质量。为 AutoDAN 设计有效的初始化策略，主要应该考虑以下两关键因素：

- 手工制作的越狱提示原型已在特定场景中证明了其有效性，它是一个宝贵的基础；因此，我们初始化的提示绝不能偏离它太远（多种维度，prompt含义、token数等等）。

- 确保初始群体的多样性至关重要，因为这可以防止过早趋同于次优解决方案（较差的局部最大值），并促进对解决方案空间的更广泛探索。

为了保留手工制作的越狱提示原型的基本特征，同时促进多样化，AutoDAN采用 LLM 作为代理，负责修改提示原型，算法原理如下图所示。

![Initialization](https://david-pigeon.github.io/notebook/images/Paper/Jail/Autodan_2.png)

这一方案的基本原理是，LLM 提出的修改意见既能保留原始句子固有的逻辑流程和含义，又能在选词和句子结构方面引入多样性。

### 损失函数的定义和性能评估

我们注意到，越狱攻击的目标可以按照方程（2）来进行建模，因此可以直接基于方程（2）来构建在遗传算法中的损失函数，该损失函数用于评估遗传算法中每个个体的似然度。AutoDAN直接使用了GCG方法中的对数似然函数来作为损失函数，对于一个给定的越狱攻击提示 $J_i$ ，损失函数为：

$$
\mathcal{L}_{\left(J_i\right)}=-log(P\left(r_{m+1},r_{m+2},\cdots,r_{m+k}|t_1,t_2,\cdots,t_m\right))\;\;\;\;(3)
$$

注意到遗传算法的目标是为了找到适应度更高的个体，AutoDAN为保持和遗传算法的一致性，定义适应性分数函数为 $S_{\left(J_i\right)}=-\mathcal{L}_{\left(J_i\right)}$。

### 基于遗传算法的AutoDAN-GA

基于上文的初始化策略和适应性评估函数，可以进一步利用遗传算法来对越狱提示进行优化。通过使用多点的交叉方案，就可以实现基于遗传算法的越狱提示自动生成。我们定义的交叉变异函数如下图（算法2）

![Crossover&Mutation](https://david-pigeon.github.io/notebook/images/Paper/Jail/Autodan_4.png)

![Crossover](https://david-pigeon.github.io/notebook/images/Paper/Jail/Autodan_3.png)

直接使用遗传算法的AutoDAN算法实现如算法3所示：

![AutoDAN-GA](https://david-pigeon.github.io/notebook/images/Paper/Jail/Autodan_5.png)

### 分层遗传算法AutoDAN-HGA

上文基于初始化方案和适应度评价函数，利用最为简单的遗传算法实现了越狱提示的自动化。之后AutoDAN提出了新方法，即利用离散文本数据的固有特征，制定更有效的策略来处理结构性离散文本数据。

基于文本数据具有分层结构这样一种显著的特点，AutoDAN-HGA将算法限制为越狱提示的段落级交叉而非原本的单词级别交叉，从而将搜索限制在一个单一的分层级别，在极大程度上缩小了搜索空间。因此，我们在遗传算法中也加入了分层的处理：在每次搜索迭代中，首先探索句子级种群的空间，例如单词选择，然后将句子级种群集成到段落级种群中，并在段落级空间（例如句子组合）上开始搜索。我们发现，使用分层遗传算法后，AutoDAN-HGA的在损失函数收敛性上的表现优于AutoDAN-GA。

论文提供的损失函数变化曲线（下图）表明，AutoDAN-GA 似乎以恒定的损失分数停滞不前，这表明它陷入局部最小值，而 AutoDAN-HGA 继续探索破损提示并减少损失。

![](https://david-pigeon.github.io/notebook/images/Paper/Jail/Autodan_6.png)

#### 段落级别的交叉和变异

给定由算法1初始化的种群，AutoDAN将首先根据等式 3 评估种群中每个个体的适应度得分。适应度评估后，下一步是选择个体进行交叉和突变，对应的策略如下：

假设有一个包含 $N$ 个提示的种群。给定一个精英率 $\alpha$，首先允许具有最高适应度分数的前 $\alpha\cdot N$ 个提示直接继续下一次迭代，无需进行修改，这样可以保证损失函数始终下降。随后，为了确定下一次迭代所需要的剩余的 $\left(1-\alpha\right)\cdot N$ 个提示，在选择过程我们基于Softmax函数和提示的适应度分数来确定给定提示的选择概率：

$$
P_{J_i}\ =\ \dfrac{e^{S_{j_i}}}{\sum_{j=1}^{\left(1-\alpha\right)N}e^{S_{j_i}}}
$$

选择过程之后，将有 $\left(1-\alpha\right)\cdot N$ 个“父提示”准备好进行交叉和突变，如算法2所示。

对于这其中的每一个提示，以概率 $p_{crossover}$ 来与另一个提示做交叉（选择的提示依照上面计算出的选择概率），进行多点交叉的方式可以理解为在多个断点之间交换两个提示的句子。

完成自由组合后，再以$p_{mutation}$ 的概率执行突变。这 $\left(1-\alpha\right)\cdot N$ 个“父提示”经过交叉和突变之后得到了 $\left(1-\alpha\right)\cdot N$ 个“子提示”，将这些子提示和在选择阶段筛选出的高适应度的前 $\alpha\cdot N$ 个提示合并，即可开始下一次迭代。

#### 句子级别的交叉和变异

在句子级别，搜索空间主要围绕单词的选择。类似地，首先对每个越狱提示进行适应度分数评估，并将分数的平均数作为结果分配给相应提示的中的每个单词，以此量化每个词在实现成功攻击中的重要性。为了考虑在优化过程中可能存在的适应度分数的不稳定性，AutoDAN-HGA方法再将相邻两次迭代的分数取平均作为最终的适应度分数（即论文中提到的基于动量的设计，算法4）。

![Momentum](https://david-pigeon.github.io/notebook/images/Paper/Jail/Autodan_7.png)

完成上述单词分数表的构建后，使用适应度分数前列的单词替换prompt中的近义词（算法5），即实现了句级别的交叉和变异（本质上这一部分只涉及到了交叉）。 

![Replacement](https://david-pigeon.github.io/notebook/images/Paper/Jail/Autodan_8.png)

#### 退出机制

为确保 AutoDAN 的有效性和高效率，提出以下两种退出机制：

- 达到最大迭代次数。

- 无法进行高适应度分数的近义词替换。

当达到这两种退出机制后，AutoDAN 将终止并返回当前具有最高适应度分数的最佳越狱提示。

最后，AutoDAN-HGA 在算法 6 中被描述。

![Autodan_HGA](https://david-pigeon.github.io/notebook/images/Paper/Jail/Autodan_9.png)

## 实验分析

### 实验准备

#### 数据集的选取

AutoDAN论文使用GCG中介绍的 `AdvBench` 有害行为数据集 来评估越狱攻击。该数据集包含 520 个请求，涵盖了亵渎、图形描述、威胁行为、错误信息、歧视、网络犯罪和危险或非法建议。

#### Baseline 选取

AutoDAN论文 选择最近提出的工作 GCG 攻击 28作为 baseline 方法 ，这是一种公开可用的先
进方法，用于自动生成 jailbreak 提示。此外，GCG 攻击举例说明了 token-level的优化方法，这与 AutoDAN 的思想形成对比。论文根据评估结果深入研究这种区别。其中 GCG 攻击采用官方设置，以 $1000$ 次迭代为准。

#### 评价指标

- 基于关键字的攻击成功率（ASR）。。该指标侧重于检测 LLMs 的响应中是否存在预定义的关键字。这样的关键字通常包括 "I am sorry", "As a responsible AI," 等短语。给定输入对 $< 𝐽_𝑖,𝑄_𝑖 >$ 及其对应的相应 $𝑅_𝑖$，如果 $𝑅_𝑖$ 中不存在预定义列表中的任何关键字，就可以认为攻击没有被 LLM 拒绝，并且对于对应的样本攻击是成功的。

- GPT 重新检查攻击成功率 (Recheck)。我们注意到，有时 LLM 并不直接拒绝回答恶意查询，而是提供偏离主题的内容。或者， LLM 可能会回复带有附加建议的恶意查询，例如提醒用户请求可能是非法的或不道德的。这些实例可能会导致 ASR 不精确。在这种情况下，论文选择 使用 LLM 来确定响应是否本质上是回答恶意查询。

- 标准句子困惑度（PPL）。对于恶意攻击的隐蔽性，论文通过GPT-2来评估prompt的困惑度来作为评估指标。

> 在ASR和Recheck两个指标中，我们选择 $I_{success} / I_{total}$ 来计算最后的成功率。

#### 模型选择

AutoDAN论文 使用三个开源 LLMs，包括 Vicuna-7b、 Guanaco7b和没有系统提示的 Llama2-7b-chat，来进行评估。此外还使用 GPT-3.5-turbo进一步研究了其对闭源 LLMs 的可迁移性。

### 实验结果

- 攻击效果和隐蔽性：
    - AutoDAN 可以有效地生成 jailbreak 提示，与基线方法相比，攻击成功率更高。
    - 对于鲁棒模型 Llama2，AutoDAN 系列可以将攻击成功率提高 10% 以上。
    - AutoDAN 可以达到比基线 GCG 低得多的 PPL，并且与手工制作的 DAN 相当。
    - 以上结果表明，AutoDAN 可以成功地生成隐蔽的越狱提示。

- 对抗防御的有效性
    - 困惑防御显著降低了 token-level 的越狱攻击，也就是 GCG 攻击的有效性。
    - 然而，语义上有意义的越狱提示 AutoDAN（以及原始手工制作的 DAN）不受影响。

- 越狱提示的可迁移性
    - 与 baseline相比， AutoDAN 在攻击黑盒 LLM 方面表现出更好的可迁移性。推测潜在原因是语义上有意义的jailbreak 提示可能本质上比基于标记梯度的方法更具可迁移性。

- 跨样本通用性
    - AutoDAN 的通用性评估整体基于跨样本测试协议。对于为第 $𝑖$ 个请求 $𝑄_𝑖$ 设计的 jailbreak 提示， 论文测试了其对于接下来的 20 个请求，即 $\{𝑄_{𝑖+1},...,𝑄_{𝑖+20}\} 的攻击有效性。与 baseline 相比， AutoDAN 也可以获得更高的通用性。该结果还表明，语义上有意义的 jailbreak 不仅在不同模型之间具有更高的可迁移性，而且在数据实例之间具有更高的可迁移性。





